"""
äººè‡‰æª¢æ¸¬å’Œé®è”½æ¨¡çµ„ - ONNXç‰ˆæœ¬ï¼ˆè¼•é‡åŒ–ï¼‰
ä½¿ç”¨YOLO10m + ONNX Runtimeä»£æ›¿PyTorchï¼Œé«”ç©æ¸›å°‘90%ä»¥ä¸Š
"""

import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import os
import onnxruntime as ort


class FaceBlurToolONNX:
    def __init__(self, model_path="Yolo10m/model.onnx"):
        """åˆå§‹åŒ–äººè‡‰æª¢æ¸¬å·¥å…·ï¼ˆONNXç‰ˆæœ¬ï¼Œä½¿ç”¨YOLO10mï¼‰

        Args:
            model_path: ONNXæ¨¡å‹æª”æ¡ˆè·¯å¾‘
        """
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}")

        # è¼‰å…¥ONNXæ¨¡å‹
        self.session = ort.InferenceSession(
            model_path,
            providers=['CPUExecutionProvider']  # ä½¿ç”¨CPU
        )

        # ç²å–è¼¸å…¥è¼¸å‡ºåç¨±
        self.input_name = self.session.get_inputs()[0].name
        self.output_names = [output.name for output in self.session.get_outputs()]

        # å¯æ„›çš„emojiæ¸…å–®
        self.emojis = ["ğŸ˜Š", "ğŸ¥°", "ğŸ˜„", "ğŸ˜ƒ", "ğŸ˜", "ğŸ¤—", "ğŸ˜º", "ğŸ˜¸"]

        # YOLOè¼¸å…¥å¤§å°
        self.input_size = 640

    def preprocess_image(self, img):
        """é è™•ç†åœ–ç‰‡ç‚ºYOLOè¼¸å…¥æ ¼å¼

        Args:
            img: OpenCVåœ–ç‰‡

        Returns:
            è™•ç†å¾Œçš„åœ–ç‰‡æ•¸æ“š
        """
        # èª¿æ•´å¤§å°
        img_resized = cv2.resize(img, (self.input_size, self.input_size))

        # BGRè½‰RGB
        img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)

        # æ­¸ä¸€åŒ–åˆ°[0,1]
        img_normalized = img_rgb.astype(np.float32) / 255.0

        # è½‰æ›ç‚ºNCHWæ ¼å¼ (batch, channels, height, width)
        img_transposed = np.transpose(img_normalized, (2, 0, 1))
        img_batch = np.expand_dims(img_transposed, axis=0)

        return img_batch

    def nms(self, boxes, scores, iou_threshold=0.5):
        """Non-Maximum Suppression éæ¿¾é‡è¤‡æ¡†"""
        if len(boxes) == 0:
            return []

        boxes = np.array(boxes)
        scores = np.array(scores)

        x1 = boxes[:, 0]
        y1 = boxes[:, 1]
        x2 = boxes[:, 2]
        y2 = boxes[:, 3]
        areas = (x2 - x1) * (y2 - y1)

        order = scores.argsort()[::-1]
        keep = []

        while order.size > 0:
            i = order[0]
            keep.append(i)

            xx1 = np.maximum(x1[i], x1[order[1:]])
            yy1 = np.maximum(y1[i], y1[order[1:]])
            xx2 = np.minimum(x2[i], x2[order[1:]])
            yy2 = np.minimum(y2[i], y2[order[1:]])

            w = np.maximum(0, xx2 - xx1)
            h = np.maximum(0, yy2 - yy1)
            inter = w * h

            iou = inter / (areas[i] + areas[order[1:]] - inter)
            inds = np.where(iou <= iou_threshold)[0]
            order = order[inds + 1]

        return keep

    def postprocess_output(self, output, img_shape, conf_threshold=0.25):
        """å¾Œè™•ç†YOLOv8è¼¸å‡º

        Args:
            output: YOLOv8æ¨¡å‹è¼¸å‡º [batch, 5, 8400]
            img_shape: åŸå§‹åœ–ç‰‡å½¢ç‹€
            conf_threshold: ç½®ä¿¡åº¦é–¾å€¼

        Returns:
            æª¢æ¸¬åˆ°çš„äººè‡‰åˆ—è¡¨
        """
        # YOLOv8è¼¸å‡ºæ ¼å¼ï¼š[batch, 5, 8400]
        # éœ€è¦è½‰ç½®æˆ [8400, 5]
        # 5 = [x_center, y_center, width, height, confidence]
        predictions = output[0].T  # è½‰ç½®ï¼š[5, 8400] -> [8400, 5]

        boxes = []
        scores = []
        orig_h, orig_w = img_shape[:2]

        # ç¸®æ”¾æ¯”ä¾‹
        scale_x = orig_w / self.input_size
        scale_y = orig_h / self.input_size

        for pred in predictions:
            # æå–ç½®ä¿¡åº¦ï¼ˆç¬¬5å€‹å…ƒç´ ï¼Œç´¢å¼•4ï¼‰
            confidence = pred[4]

            # è·³éä½ç½®ä¿¡åº¦
            if confidence < conf_threshold:
                continue

            # æå–ä¸­å¿ƒé»å’Œå¯¬é«˜
            x_center, y_center, width, height = pred[:4]

            # è½‰æ›ç‚ºè§’é»åº§æ¨™
            x1 = x_center - width / 2
            y1 = y_center - height / 2
            x2 = x_center + width / 2
            y2 = y_center + height / 2

            # ç¸®æ”¾å›åŸåœ–å°ºå¯¸
            x1 = int(x1 * scale_x)
            y1 = int(y1 * scale_y)
            x2 = int(x2 * scale_x)
            y2 = int(y2 * scale_y)

            # é™åˆ¶åœ¨åœ–ç‰‡ç¯„åœå…§
            x1 = max(0, min(x1, orig_w))
            y1 = max(0, min(y1, orig_h))
            x2 = max(0, min(x2, orig_w))
            y2 = max(0, min(y2, orig_h))

            # ç¢ºä¿é‚Šç•Œæ¡†æœ‰æ•ˆ
            if x2 <= x1 or y2 <= y1:
                continue

            boxes.append([x1, y1, x2, y2])
            scores.append(confidence)

        # æ‡‰ç”¨ NMS éæ¿¾é‡è¤‡æ¡†
        keep_indices = self.nms(boxes, scores, iou_threshold=0.5)

        faces = []
        for idx in keep_indices:
            x1, y1, x2, y2 = boxes[idx]
            area = (x2 - x1) * (y2 - y1)
            faces.append({
                "bbox": [x1, y1, x2, y2],
                "area": float(area),
                "confidence": float(scores[idx])
            })

        return faces

    def detect_faces(self, image_path):
        """æª¢æ¸¬åœ–ç‰‡ä¸­çš„æ‰€æœ‰äººè‡‰

        Args:
            image_path: åœ–ç‰‡æª”æ¡ˆè·¯å¾‘

        Returns:
            tuple: (åŸå§‹åœ–ç‰‡, æª¢æ¸¬çµæœåˆ—è¡¨)
        """
        # è®€å–åœ–ç‰‡
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"ç„¡æ³•è®€å–åœ–ç‰‡: {image_path}")

        # é è™•ç†
        input_data = self.preprocess_image(img)

        # åŸ·è¡Œæ¨ç†
        outputs = self.session.run(self.output_names, {self.input_name: input_data})

        # å¾Œè™•ç†
        faces = self.postprocess_output(outputs[0], img.shape)

        # æŒ‰é¢ç©å¾å¤§åˆ°å°æ’åº
        faces.sort(key=lambda x: x["area"], reverse=True)

        # æ–°å¢ç·¨è™Ÿ
        for i, face in enumerate(faces, 1):
            face["id"] = i

        return img, faces

    def draw_face_boxes(self, img, faces, selected_ids=None):
        """åœ¨åœ–ç‰‡ä¸Šç¹ªè£½äººè‡‰æ¡†å’Œç·¨è™Ÿ

        Args:
            img: åŸå§‹åœ–ç‰‡(numpy array)
            faces: äººè‡‰æª¢æ¸¬çµæœåˆ—è¡¨
            selected_ids: é¸ä¸­è¦é®è”½çš„äººè‡‰IDåˆ—è¡¨

        Returns:
            numpy array: ç¹ªè£½äº†äººè‡‰æ¡†çš„åœ–ç‰‡
        """
        img_with_boxes = img.copy()

        for face in faces:
            x1, y1, x2, y2 = face["bbox"]
            face_id = face["id"]
            area = face["area"]

            # å¦‚æœè©²äººè‡‰è¢«é¸ä¸­ï¼Œä½¿ç”¨ç´…è‰²æ¡†ï¼Œå¦å‰‡ä½¿ç”¨ç¶ è‰²æ¡†
            color = (0, 0, 255) if (selected_ids and face_id in selected_ids) else (0, 255, 0)
            thickness = 3 if (selected_ids and face_id in selected_ids) else 2

            # ç¹ªè£½çŸ©å½¢æ¡†
            cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, thickness)

            # ç¹ªè£½ç·¨è™Ÿå’Œéºµç©è³‡è¨Š
            label = f"#{face_id} ({int(area)}pxÂ²)"
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.6
            font_thickness = 2

            # è¨ˆç®—æ–‡å­—å¤§å°
            (text_width, text_height), baseline = cv2.getTextSize(
                label, font, font_scale, font_thickness
            )

            # ç¹ªè£½æ–‡å­—èƒŒæ™¯
            cv2.rectangle(
                img_with_boxes,
                (x1, y1 - text_height - 10),
                (x1 + text_width + 5, y1),
                color,
                -1
            )

            # ç¹ªè£½æ–‡å­—
            cv2.putText(
                img_with_boxes,
                label,
                (x1 + 2, y1 - 5),
                font,
                font_scale,
                (255, 255, 255),
                font_thickness
            )

        return img_with_boxes

    def blur_faces_with_emoji(self, img, faces, start_id, end_id):
        """ä½¿ç”¨emojié®è”½æŒ‡å®šç¯„åœçš„äººè‡‰

        Args:
            img: åŸå§‹åœ–ç‰‡(numpy array)
            faces: äººè‡‰æª¢æ¸¬çµæœåˆ—è¡¨
            start_id: é–‹å§‹é®è”½çš„äººè‡‰ç·¨è™Ÿ
            end_id: çµæŸé®è”½çš„äººè‡‰ç·¨è™Ÿ

        Returns:
            numpy array: é®è”½å¾Œçš„åœ–ç‰‡
        """
        # è½‰æ›ç‚ºPILåœ–ç‰‡ä»¥ä¾¿ç¹ªè£½emoji
        img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(img_pil)

        # è¼‰å…¥å­—å‹ï¼ˆå˜—è©¦ä½¿ç”¨ç³»çµ±emojiå­—å‹ï¼‰
        font_size = 100
        try:
            # Windowsç³»çµ±çš„emojiå­—å‹
            font_paths = [
                "C:/Windows/Fonts/seguiemj.ttf",  # Segoe UI Emoji
                "C:/Windows/Fonts/NotoColorEmoji.ttf",
                "C:/Windows/Fonts/seguisym.ttf"
            ]
            font = None
            for font_path in font_paths:
                if os.path.exists(font_path):
                    font = ImageFont.truetype(font_path, font_size)
                    break

            if font is None:
                # å¦‚æœæ‰¾ä¸åˆ°å­—å‹ï¼Œä½¿ç”¨é è¨­å­—å‹
                font = ImageFont.load_default()
        except Exception:
            font = ImageFont.load_default()

        # é®è”½é¸å®šç¯„åœçš„äººè‡‰
        emoji_index = 0
        for face in faces:
            face_id = face["id"]

            # æª¢æŸ¥æ˜¯å¦åœ¨é®è”½ç¯„åœå…§
            if start_id <= face_id <= end_id:
                x1, y1, x2, y2 = face["bbox"]

                # è¨ˆç®—äººè‡‰ä¸­å¿ƒé»
                center_x = (x1 + x2) // 2
                center_y = (y1 + y2) // 2

                # è¨ˆç®—emojiå¤§å°ï¼ˆæ ¹æ“šäººè‡‰å¤§å°èª¿æ•´ï¼‰
                face_width = x2 - x1
                face_height = y2 - y1
                emoji_size = int(max(face_width, face_height) * 1.2)

                # èª¿æ•´å­—å‹å¤§å°
                try:
                    if isinstance(font, ImageFont.FreeTypeFont):
                        emoji_font = ImageFont.truetype(font.path, emoji_size)
                    else:
                        emoji_font = font
                except Exception:
                    emoji_font = font

                # é¸æ“‡emoji
                emoji = self.emojis[emoji_index % len(self.emojis)]
                emoji_index += 1

                # ç¹ªè£½emojiï¼ˆè¨ˆç®—ä½ç½®ä½¿å…¶å±…ä¸­ï¼‰
                bbox = draw.textbbox((0, 0), emoji, font=emoji_font)
                text_width = bbox[2] - bbox[0]
                text_height = bbox[3] - bbox[1]

                text_x = center_x - text_width // 2
                text_y = center_y - text_height // 2

                draw.text((text_x, text_y), emoji, font=emoji_font, embedded_color=True)

        # è½‰æ›å›OpenCVæ ¼å¼
        img_with_emoji = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

        return img_with_emoji

    def get_face_info(self, faces):
        """ç²å–äººè‡‰è³‡è¨Šçš„æ–‡å­—æè¿°

        Args:
            faces: äººè‡‰æª¢æ¸¬çµæœåˆ—è¡¨

        Returns:
            str: äººè‡‰è³‡è¨Šæè¿°
        """
        if not faces:
            return "æœªæª¢æ¸¬åˆ°äººè‡‰"

        info = f"æª¢æ¸¬åˆ° {len(faces)} å€‹äººè‡‰ï¼ˆæŒ‰é¢ç©å¾å¤§åˆ°å°æ’åºï¼‰:\n\n"
        for face in faces:
            info += f"#{face['id']}: é¢ç©={int(face['area'])}pxÂ², ç½®ä¿¡åº¦={face['confidence']:.2f}\n"

        return info


# ç‚ºäº†å…¼å®¹æ€§ï¼Œå‰µå»ºåˆ¥å
FaceBlurTool = FaceBlurToolONNX
